{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a87ec01-5fe6-48e0-88ae-f5bf077c9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 12:04:29: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-10-14 12:04:29: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-10-14 12:04:29: oggm.cfg: Multiprocessing: using all available processors (N=32)\n",
      "2024-10-14 12:04:31: oggm.workflow: init_glacier_directories by parsing all available folders (this takes time: if possible, provide rgidf instead).\n"
     ]
    }
   ],
   "source": [
    "from oggm import utils\n",
    "import copy\n",
    "import numpy as np\n",
    "from get_reference_glaciers import get_fl_at_year\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de44e24-6047-46c1-a019-e3a95425b7ff",
   "metadata": {},
   "source": [
    "# get statistics for single interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43138e57-1894-4dff-b07c-0fca48d250dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_single_iteration(iter, fl_runs, sfc_h_starts, glacier, glacier_state):\n",
    "    fl_ref_1980 = get_fl_at_year(glacier, glacier_state, 1980)\n",
    "    fl_ref_2020 = get_fl_at_year(glacier, glacier_state, 2020)\n",
    "\n",
    "    if iter > fl_runs.iteration[-1]:\n",
    "        iter = fl_runs.iteration[-1]\n",
    "\n",
    "    fl = fl_runs.isel(iteration=iter).item()\n",
    "    sfc_h_start = sfc_h_starts.isel(iteration=iter)\n",
    "\n",
    "    def get_volume(fl):\n",
    "        return fl.section * fl.dx_meter\n",
    "\n",
    "    mad_today_volume= utils.mad(\n",
    "            get_volume(fl_ref_2020),\n",
    "            get_volume(fl)\n",
    "        )\n",
    "\n",
    "    mad_bed_h = utils.mad(\n",
    "            fl_ref_2020.bed_h,\n",
    "            fl.bed_h\n",
    "        )\n",
    "\n",
    "    #now recreate initial flowline state\n",
    "    fl.surface_h = sfc_h_start\n",
    "    mad_past_volume = utils.mad(\n",
    "            get_volume(fl_ref_1980),\n",
    "            get_volume(fl)\n",
    "        )\n",
    "\n",
    "    return mad_today_volume, mad_bed_h, mad_past_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3aa99-d469-41ae-a758-f08763eed41a",
   "metadata": {},
   "source": [
    "# Get statistics for all iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33c053a-d92e-4554-ac0b-4cca99ea7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_all_iterations(ds, glacier, glacier_state, ds_ref=None):\n",
    "\n",
    "    fl_run = copy.deepcopy(ds.flowlines)\n",
    "    sfc_h_starts = copy.deepcopy(ds.sfc_h_start)\n",
    "\n",
    "    if ds_ref is None:\n",
    "        ds_ref = ds\n",
    "\n",
    "    mad_today_volume_ref, mad_bed_h_ref, mad_past_volume_ref = get_stats_for_single_iteration(\n",
    "        0,\n",
    "        copy.deepcopy(ds_ref.flowlines),\n",
    "        copy.deepcopy(ds_ref.sfc_h_start),\n",
    "        glacier, glacier_state)\n",
    "\n",
    "    mad_today_volume = []\n",
    "    mad_bed_h = []\n",
    "    mad_past_volume = []\n",
    "\n",
    "    for fl, iter, sfc_h_start in zip(fl_run, fl_run.iteration, sfc_h_starts):\n",
    "        mad_today_volume_single, mad_bed_h_single, mad_past_volume_single = get_stats_for_single_iteration(\n",
    "            iter, fl_run, sfc_h_starts, glacier, glacier_state)\n",
    "        fl = fl.item()\n",
    "        mad_today_volume.append(mad_today_volume_single)\n",
    "\n",
    "        mad_bed_h.append(mad_bed_h_single)\n",
    "\n",
    "        #now recreate initial flowline state\n",
    "        fl.surface_h = sfc_h_start\n",
    "        mad_past_volume.append(mad_past_volume_single)\n",
    "\n",
    "    # scale all by the reference\n",
    "    mad_today_volume = np.array(mad_today_volume)\n",
    "    mad_today_volume /= mad_today_volume_ref\n",
    "\n",
    "    mad_bed_h = np.array(mad_bed_h)\n",
    "    mad_bed_h /= mad_bed_h_ref\n",
    "\n",
    "    mad_past_volume = np.array(mad_past_volume)\n",
    "    mad_past_volume /= mad_past_volume_ref\n",
    "\n",
    "    return ((mad_today_volume, mad_today_volume_ref),\n",
    "            (mad_bed_h, mad_bed_h_ref),\n",
    "            (mad_past_volume, mad_past_volume_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4b567-97ca-43c1-a9b1-15ffa6fac600",
   "metadata": {},
   "source": [
    "# Get stats matrix for all settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1e7e6-aa86-4da1-a463-08734e743f23",
   "metadata": {},
   "source": [
    "## get reference statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8d652-b6ea-487b-b779-0151ab37cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_stats(main_results_dir, glacier, glacier_state,\n",
    "                  lam, obs, fg_method, reg='reg0'):\n",
    "    fp_pkl = os.path.join(main_results_dir,\n",
    "                          f'{glacier}_{glacier_state}_full_run_{fg_method}_{lam}_{obs}_{reg}.pkl')\n",
    "\n",
    "    with open(fp_pkl, 'rb') as handle:\n",
    "        ds_run = pickle.load(handle)\n",
    "\n",
    "    mad_today_volume_ref, mad_bed_h_ref, mad_past_volume_ref = get_stats_for_single_iteration(\n",
    "    0,\n",
    "    ds_run.flowlines,\n",
    "    ds_run.sfc_h_start,\n",
    "    glacier,\n",
    "    glacier_state)\n",
    "\n",
    "    return mad_today_volume_ref, mad_bed_h_ref, mad_past_volume_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266bd127-21cd-47fb-ae6a-b6300fdf4664",
   "metadata": {},
   "source": [
    "## get statistics for single setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cd69a-bc0d-44ec-9298-cb6e5885fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_for_setting(main_results_dir, glacier, glacier_state, iteration,\n",
    "                          lam, obs, fg_method,\n",
    "                          mad_today_volume_ref, mad_bed_h_ref,\n",
    "                          reg='reg0'):\n",
    "\n",
    "    fp_pkl = os.path.join(main_results_dir,\n",
    "                          f'{glacier}_{glacier_state}_full_run_{fg_method}_{lam}_{obs}_{reg}.pkl')\n",
    "    \n",
    "    with open(fp_pkl, 'rb') as handle:\n",
    "        ds_run = pickle.load(handle)\n",
    "    \n",
    "    mad_today_volume, mad_bed_h, mad_past_volume = get_stats_for_single_iteration(\n",
    "        iteration,\n",
    "        ds_run.flowlines,\n",
    "        ds_run.sfc_h_start,\n",
    "        glacier,\n",
    "        glacier_state)\n",
    "    \n",
    "    return (mad_today_volume / mad_today_volume_ref,\n",
    "            mad_bed_h / mad_bed_h_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8cf40-7220-4efb-9753-4293edb7860c",
   "metadata": {},
   "source": [
    "## create matrices of statistics for all settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e22b9d-855f-40b5-8103-04cd85c1026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_matrices(main_results_dir, glacier, glacier_state, iteration,\n",
    "                         experiment_options,\n",
    "                         fg_method='fg_oggm',\n",
    "                         check_ref_values=False):\n",
    "\n",
    "    if len(experiment_options['regularisation_terms']) > 1:\n",
    "        raise ValueError('Only working for a single regularisation setting!')\n",
    "\n",
    "    reg = list(experiment_options['regularisation_terms'].keys())[0]\n",
    "\n",
    "    if check_ref_values:\n",
    "        mad_today_volume_general_ref = None\n",
    "        mad_bed_h_general_ref = None\n",
    "        for lam in experiment_options['cost_lambda']:\n",
    "            for obs in experiment_options['observations']:\n",
    "                mad_today_volume_ref, mad_bed_h_ref, mad_past_volume_ref = get_ref_stats(\n",
    "                    main_results_dir,\n",
    "                    glacier, glacier_state,\n",
    "                    lam, obs, fg_method, reg=reg)\n",
    "        \n",
    "                if mad_today_volume_general_ref is None:\n",
    "                    mad_today_volume_general_ref = mad_today_volume_ref\n",
    "                    mad_bed_h_general_ref = mad_bed_h_ref\n",
    "                    continue\n",
    "        \n",
    "                diff_today_vol = mad_today_volume_ref - mad_today_volume_general_ref\n",
    "                diff_bed_h = mad_bed_h_ref - mad_bed_h_general_ref\n",
    "        \n",
    "                assert diff_today_vol == 0, diff_today_vol\n",
    "                assert diff_bed_h == 0, diff_bed_h\n",
    "\n",
    "    mad_today_volume_ref, mad_bed_h_ref, mad_past_volume_ref = get_ref_stats(\n",
    "        main_results_dir,\n",
    "        glacier, glacier_state, 'lam0', 'obs0', fg_method, reg=reg)\n",
    "\n",
    "    lambda_values = list(experiment_options['cost_lambda'].keys())\n",
    "    observation_values = list(experiment_options['observations'].keys())\n",
    "\n",
    "    # Initialize matrices for the two output statistics\n",
    "    mad_today_volume_matrix = np.zeros((len(lambda_values), len(observation_values)))\n",
    "    mad_bed_h_matrix = np.zeros((len(lambda_values), len(observation_values)))\n",
    "\n",
    "    for i, lambda_val in enumerate(lambda_values):\n",
    "        for j, obs_val in enumerate(observation_values):\n",
    "            mad_today_v, mad_bed_h = get_stats_for_setting(\n",
    "                main_results_dir,\n",
    "                glacier, glacier_state, iteration,\n",
    "                lambda_val, obs_val, fg_method,\n",
    "                mad_today_volume_ref, mad_bed_h_ref,\n",
    "                reg=reg\n",
    "            )\n",
    "            mad_today_volume_matrix[i, j] = mad_today_v\n",
    "            mad_bed_h_matrix[i, j] = mad_bed_h\n",
    "\n",
    "    return mad_today_volume_matrix, mad_bed_h_matrix, lambda_values, observation_values"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env]",
   "language": "python",
   "name": "conda-env-oggm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
